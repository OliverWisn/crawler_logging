# Simple crawler with the exceptions handling and the logging

## Motivation:
I make this script because I learn the web scraping. I would like to 
walk through the Python Standard Library + beautifulsoup and logging. 

## Requirements: 
python 3.9 - rest in requirements.txt .

## Remarks:
I make this script so that the master branch has always 
the functioning code. To run the script you must run the file
"getWikiLinks_with_logging.py".

## Script Summary:
The script is getting Wiki link and is saving it in the file 
getWikiLinks_with_logging.txt. Next he is taking the next random link 
from the site, is checking if the link has not been downloaded once, is 
saving it and is getting Wiki links from the new site. The program 
works in the endless loop.

## Version:
The basic version of the code has tag 1.0.
